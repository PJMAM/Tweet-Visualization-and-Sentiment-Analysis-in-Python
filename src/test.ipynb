{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x1b730c58c48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from tracemalloc import Snapshot\n",
    "sys.path.append(\".\")\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials,firestore,db\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "cred = credentials.Certificate('.//keys//new-admin.json')\n",
    "# Initialize the app with a service account, granting admin privileges\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://twitter-e939f-default-rtdb.firebaseio.com/\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 10:36:11\n",
      "2022-11-12 10:36:06\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import settings\n",
    "ref =db.reference('object')\n",
    "docs=ref.get()\n",
    "data=[]\n",
    "for key,val in docs.items():\n",
    "    data.append(val)\n",
    "    \n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "# Convert UTC into PDT\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Clean and transform data to enable time series\n",
    "result = df.groupby([pd.Grouper(key='created_at', freq='10s'), 'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "result = result.rename(columns={\"id\": \"Num of '{}' mentions\".format(settings.TRACK_WORDS[0]), \"created_at\":\"Time\"})  \n",
    "time_series = result[\"Time\"][result['polarity']==0].reset_index(drop=True)\n",
    "\n",
    "min10 = (datetime.datetime.now() - datetime.timedelta(hours=7 ,minutes=10)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(min10)\n",
    "min20 = (datetime.datetime.now() - datetime.timedelta(hours=7,minutes=10,seconds=5)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(min20)\n",
    "neu_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].sum()\n",
    "neg_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].sum()\n",
    "pos_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 17:48:32.728781\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count_now = df[df['created_at'] > min10]['id'].count()\n",
    "count_before = df[ (min20 < df['created_at']) & (df['created_at'] < min10)]['id'].count() \n",
    "print(count_now)\n",
    "print(count_before)\n",
    "print(np.uint64(count_now)/np.uint64(count_now)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-12 10:03:53'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=db.reference('Backup')\n",
    "docs=ref.get()\n",
    "type(docs)\n",
    "docs=pd.DataFrame(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.update({\n",
    "    \n",
    "    'daily_user_num': 1,\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "ref=db.reference('object')\n",
    "docs= ref.get()\n",
    "\n",
    "print(dir(ref.get()))\n",
    "print(type(docs.items()))\n",
    "data=[]\n",
    "for key,val in docs.items():\n",
    "    data.append(val)\n",
    "df= pd.DataFrame(data)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] \n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import datetime\n",
    "ref =db.reference('object')\n",
    "docs=ref.get()\n",
    "data=[]\n",
    "for key,val in docs.items():\n",
    "    data.append(val)\n",
    "    \n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "# Convert UTC into PDT\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Clean and transform data to enable time series\n",
    "result = df.groupby([pd.Grouper(key='created_at', freq='10s'), 'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "result = result.rename(columns={\"id\": \"Num of '{}' mentions\".format(settings.TRACK_WORDS[0]), \"created_at\":\"Time\"})  \n",
    "time_series = result[\"Time\"][result['polarity']==0].reset_index(drop=True)\n",
    "\n",
    "min10 = datetime.datetime.now() - datetime.timedelta(hours=7,minutes=40)\n",
    "min20 = datetime.datetime.now() - datetime.timedelta(minutes=5)\n",
    "\n",
    "neu_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].sum()\n",
    "neg_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].sum()\n",
    "pos_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2022-11-12 09:33:00\n",
       "Name: Time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Time'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-12 08:54:29'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min10.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "Name: Time, dtype: bool"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Time']>min10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      8\n",
       "2      8\n",
       "3      3\n",
       "4     20\n",
       "5      3\n",
       "6      3\n",
       "7     14\n",
       "8     11\n",
       "9      4\n",
       "10    14\n",
       "11     6\n",
       "12     4\n",
       "13    27\n",
       "14     4\n",
       "15     5\n",
       "16    19\n",
       "17     5\n",
       "18     3\n",
       "19    17\n",
       "20     8\n",
       "21     5\n",
       "22    18\n",
       "23    12\n",
       "24     4\n",
       "25    23\n",
       "26     8\n",
       "27     4\n",
       "28    21\n",
       "29     7\n",
       "30     3\n",
       "31    19\n",
       "32     6\n",
       "33     0\n",
       "34     3\n",
       "35     1\n",
       "Name: Num of 'Facebook' mentions, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "neu_num_1 = result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])]\n",
    "neu_num_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "ref =db.reference('object')\n",
    "docs=ref.get()\n",
    "data=[]\n",
    "for key,val in docs.items():\n",
    "    data.append(val)\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "# Convert UTC into PDT\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Clean and transform data to enable time series\n",
    "result = df.groupby([pd.Grouper(key='created_at', freq='10s'), 'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "result = result.rename(columns={\"id\": \"Num of '{}' mentions\".format(settings.TRACK_WORDS[0]), \"created_at\":\"Time\"})  \n",
    "time_series = result[\"Time\"][result['polarity']==0].reset_index(drop=True)\n",
    "\n",
    "min10 = datetime.datetime.now() - datetime.timedelta(seconds=10)\n",
    "min20 = datetime.datetime.now() - datetime.timedelta(seconds=20)\n",
    "\n",
    "neu_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].sum()\n",
    "neg_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].sum()\n",
    "pos_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].sum()\n",
    "\n",
    "count_now = df[df['created_at'] > min10]['id'].count()\n",
    "count_before = df[ (min20 < df['created_at']) & (df['created_at'] < min10)]['id'].count()\n",
    "percent = (count_now-count_before)/count_before*100\n",
    "\n",
    "ref_backUp =db.reference('Backup')\n",
    "back_up=ref_backUp.get()\n",
    "a={}\n",
    "for key,val in back_up.items() :\n",
    "    a[key]=val\n",
    "\n",
    "\n",
    "back_up_dict =pd.DataFrame(a,index=[0])\n",
    "\n",
    "daily_tweets_num = int (back_up_dict['daily_tweets_num'].iloc[0] + result[-6:-3][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])].sum())\n",
    "daily_impressions = int(back_up_dict['impressions'].iloc[0] + df[df['created_at'] > (datetime.datetime.now() - datetime.timedelta(minutes=10))]['user_followers_count'].sum())\n",
    "\n",
    "PDT_now = datetime.datetime.now() - datetime.timedelta(minutes=10)\n",
    "if PDT_now.strftime(\"%H%M\")=='0000':\n",
    "    # cur.execute(\"UPDATE Back_Up SET daily_tweets_num = 0, impressions = 0;\")\n",
    "    ref_backUp.update({'daily_tweets_num': 0,'impressions':0})\n",
    "\n",
    "else:\n",
    "    # cur.execute(\"UPDATE Back_Up SET daily_tweets_num = {}, impressions = {};\".format(daily_tweets_num, daily_impressions))\n",
    "    ref_backUp.update({'daily_tweets_num':daily_tweets_num,\\\n",
    "                        'impressions':daily_impressions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "min10 = datetime.datetime.now() - datetime.timedelta(minutes=10)\n",
    "min10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_backUp =db.reference('Backup')\n",
    "back_up=ref_backUp.get()\n",
    "back_up_dict={}\n",
    "for key,val in back_up.items() :\n",
    "    back_up_dict[key]=val\n",
    "test= pd.DataFrame(back_up_dict,index=[0])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.renamresult = df.groupby([pd.Grouper(key='created_at', freq='2s'), 'polarity'] ).count().unstack(fill_value=0).stack().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={ \"id\": \"Num of Facebook mentions\",\"created_at\":\"Time in UTC\" })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = result[\"Time in UTC\"][result['polarity']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_num = result[result['Time']>min10][\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(result, x='Time in UTC',y=\"Num of Facebook mentions\",color='polarity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = ' '.join(df[\"text\"])\n",
    "content = re.sub(r\"http\\S+\", \"\", content)\n",
    "content = content.replace('RT ', ' ').replace('&amp;', 'and')\n",
    "content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "content = content.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "tokenized_word = word_tokenize(content)\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_sent=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "fdist = FreqDist(filtered_sent)\n",
    "fd = pd.DataFrame(fdist.most_common(10),                    \\\n",
    "    columns = [\"Word\",\"Frequency\"]).drop([0]).reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(fd, x=\"Word\", y=\"Frequency\")\n",
    "fig.update_traces(marker_color='rgb(240,128,128)',          \\\n",
    "    marker_line_color='rgb(8,48,107)',                      \\\n",
    "    marker_line_width=1.5, opacity=0.8)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "STATES = ['Alabama', 'AL', 'Alaska', 'AK', 'American Samoa', 'AS', 'Arizona', 'AZ', 'Arkansas', 'AR', 'California', 'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'District of Columbia', 'DC', 'Federated States of Micronesia', 'FM', 'Florida', 'FL', 'Georgia', 'GA', 'Guam', 'GU', 'Hawaii', 'HI', 'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS', 'Kentucky', 'KY', 'Louisiana', 'LA', 'Maine', 'ME', 'Marshall Islands', 'MH', 'Maryland', 'MD', 'Massachusetts', 'MA', 'Michigan', 'MI', 'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', 'Nebraska', 'NE', 'Nevada', 'NV', 'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', 'New York', 'NY', 'North Carolina', 'NC', 'North Dakota', 'ND', 'Northern Mariana Islands', 'MP', 'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Palau', 'PW', 'Pennsylvania', 'PA', 'Puerto Rico', 'PR', 'Rhode Island', 'RI', 'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', 'Utah', 'UT', 'Vermont', 'VT', 'Virgin Islands', 'VI', 'Virginia', 'VA', 'Washington', 'WA', 'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']\n",
    "STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=\"\"))\n",
    "INV_STATE_DICT = dict((v,k) for k,v in STATE_DICT.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_US=[]\n",
    "geo = df[['user_location']]\n",
    "df = df.fillna(\" \")\n",
    "for x in df['user_location']:\n",
    "    check = False\n",
    "    for s in STATES:\n",
    "        if s in x:\n",
    "            is_in_US.append(STATE_DICT[s] if s in STATE_DICT else s)\n",
    "            check = True\n",
    "            break\n",
    "    if not check:\n",
    "        is_in_US.append(None)\n",
    "\n",
    "geo_dist = pd.DataFrame(is_in_US, columns=['State'])           \\\n",
    "    .dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "geo_dist = geo_dist.groupby('State').count().rename(columns={\"index\": \"Number\"}).sort_values(by=['Number'], ascending=False).reset_index()\n",
    "geo_dist[\"Log Num\"] = geo_dist[\"Number\"].apply(lambda x: math.log(x, 2))\n",
    "geo_dist['Full State Name'] = geo_dist['State'].apply(lambda x: INV_STATE_DICT[x])\n",
    "geo_dist['text'] = geo_dist['Full State Name'] + '<br>' + 'Num: ' + geo_dist['Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=geo_dist['State'], # Spatial coordinates\n",
    "    z = geo_dist['Log Num'].astype(float), # Data to be color-coded\n",
    "\n",
    "    locationmode = 'USA-states', \n",
    "    colorscale = \"Reds\",\n",
    "    text=geo_dist['text'],\n",
    "    marker_line_color='white', # line markers between states\n",
    "    colorbar_title = \"Numbers in Log2\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    geo_scope='usa', \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        column_widths=[1, 0.4],\n",
    "        row_heights=[0.6, 0.4],\n",
    "        specs=[[{\"type\": \"scatter\", \"rowspan\": 2}, \n",
    "                {\"type\": \"choropleth\"}],\n",
    "               [None, {\"type\": \"bar\"}]]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Scatter(\n",
    "    x=time_series,\n",
    "    y=result[\"Num of Facebook mentions\"] [result['polarity']==0].reset_index(drop=True),  opacity=0.8), row=1, col=1)   \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=time_series,\n",
    "    y=result[\"Num of Facebook mentions\"] [result['polarity']==-1].reset_index(drop=True),\n",
    "    name=\"Negative\",\n",
    "    opacity=0.8), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=time_series,\n",
    "    y=result[\"Num of Facebook mentions\" ][result['polarity']==1].reset_index(drop=True), \\\n",
    "    name=\"Positive\",\n",
    "    opacity=0.8), row=1, col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Bar(x=fd[\"Word\"], y=fd[\"Frequency\"],       \\\n",
    "    name=\"Freq Dist\"), row=2, col=2)\n",
    "\n",
    "fig.update_traces(marker_color='rgb(59, 89, 152)',          \\\n",
    "    marker_line_color='rgb(8,48,107)',                      \\\n",
    "    marker_line_width=0.5, opacity=0.7, row=2, col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Choropleth(\n",
    "    locations=geo_dist['State'], # Spatial coordinates\n",
    "    z = geo_dist['Log Num'].astype(float), # Data to be color-coded\n",
    "    locationmode = 'USA-states', \n",
    "    colorscale = \"Blues\",\n",
    "    text=geo_dist['text'], # hover text\n",
    "    showscale=False,\n",
    "    geo = 'geo'\n",
    "    ), row=1, col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "fig.update_layout(\n",
    "    title_text =                                            \\\n",
    "      \"Real-time tracking '{}' mentions on Twitter {} UTC\"  \\\n",
    "      .format('Facebook'       \n",
    "        ,datetime.datetime.utcnow().strftime('%m-%d %H:%M') \\\n",
    "      ),\n",
    "    geo = dict(\n",
    "        scope='usa',\n",
    "    ),\n",
    "    template=\"plotly_dark\",\n",
    "    margin=dict(r=20, t=50, b=50, l=20),\n",
    "    annotations=[\n",
    "        go.layout.Annotation(\n",
    "            text=\"Source: Twitter\",\n",
    "            showarrow=False,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0,\n",
    "            y=0)\n",
    "    ],\n",
    "    showlegend=False,\n",
    "    xaxis_rangeslider_visible=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89ac92df1ee86809fe3c4d9fa5ef8c4cba542d124b321da4e13b2743178da785"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
